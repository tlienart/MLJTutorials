<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/libs/highlight/github.min.css">
   
  <link rel="stylesheet" href="/css/judoc.css">
  <link rel="stylesheet" href="/css/pure.css">
  <link rel="stylesheet" href="/css/side-menu.css">
  <link rel="stylesheet" href="/css/extra.css">
  <link rel="icon" href="/assets/infra/favicon.ico">
   <title></title>  
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/" id="menu-logo-link">
          <div class="menu-logo">
            <img id="menu-logo" alt="MLJ Logo" src="/assets/infra/MLJLogo2.svg" />
            <p><strong>MLJ Tutorials</strong></p>
          </div>
        </a>
        <ul class="pure-menu-list">
          <li class="pure-menu-item pure-menu-top-item "><a href="/" class="pure-menu-link"><strong>Home</strong></a></li>

          <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
          <ul class="pure-menu-sublist">
            <li class="pure-menu-item "><a href="/pub/getting-started/choosing-a-model.html" class="pure-menu-link">‚ä≥ Choosing a model</a></li>
            <li class="pure-menu-item pure-menu-selected"><a href="/pub/getting-started/fit-and-predict.html" class="pure-menu-link">‚ä≥ Fit, predict, transform</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/model-tuning.html" class="pure-menu-link">‚ä≥ Model tuning</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/composing-models.html" class="pure-menu-link">‚ä≥ Composing models</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/learning-networks.html" class="pure-menu-link">‚ä≥ Learning networks</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
          <ul class="pure-menu-sublist">
            <li class="pure-menu-item "><a href="/pub/end-to-end/AMES.html" class="pure-menu-link">‚ä≥ AMES</a></li>
          </ul>
        </ul>
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->

<div class="jd-content">
<h1 id="fit_predict_transform"><a href="/pub/getting-started/fit-and-predict.html#fit_predict_transform">Fit, predict, transform</a></h1>
<em>Download the</em> <a href="https://raw.githubusercontent.com/tlienart/MLJTutorials/gh-pages/notebooks/A-fit-predict.ipynb" target="_blank"><em>notebook</em></a> <em>or the</em> <a href="https://raw.githubusercontent.com/tlienart/MLJTutorials/gh-pages/scripts/A-fit-predict.jl" target="_blank"><em>raw script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> </p>
<div class="jd-toc"><ol><li><a href="/pub/getting-started/fit-and-predict.html#fit_predict_transform">Fit, predict, transform</a><ol><li><a href="/pub/getting-started/fit-and-predict.html#preliminary_steps">Preliminary steps</a><ol><li><a href="/pub/getting-started/fit-and-predict.html#data">Data</a></li><li><a href="/pub/getting-started/fit-and-predict.html#mlj_machine">MLJ Machine</a></li></ol></li><li><a href="/pub/getting-started/fit-and-predict.html#training_and_testing_a_supervised_model">Training and testing a supervised model</a><ol><li><a href="/pub/getting-started/fit-and-predict.html#splitting_the_data">Splitting the data</a></li><li><a href="/pub/getting-started/fit-and-predict.html#fitting_and_testing_the_machine">Fitting and testing the machine</a></li></ol></li><li><a href="/pub/getting-started/fit-and-predict.html#unsupervised_models">Unsupervised models</a></li></ol></li></ol></div>
 <h2 id="preliminary_steps"><a href="/pub/getting-started/fit-and-predict.html#preliminary_steps">Preliminary steps</a></h2>
<h3 id="data"><a href="/pub/getting-started/fit-and-predict.html#data">Data</a></h3>
<p>As in &quot;<a href="choosing-a-model.html">choosing a model</a>&quot;, let&#39;s load the Iris dataset and unpack it:</p>
<pre><code class="language-julia">using MLJ, Statistics
X, y = @load_iris;</code></pre>
<p>let&#39;s also load the <code>DecisionTreeClassifier</code>:</p>
<pre><code class="language-julia">@load DecisionTreeClassifier</code></pre><div class="code_output"><pre><code class="plaintext">[34mDecisionTreeClassifier @ 1‚Ä¶18[39m</code></pre></div>
<h3 id="mlj_machine"><a href="/pub/getting-started/fit-and-predict.html#mlj_machine">MLJ Machine</a></h3>
<p>In MLJ, remember that a <em>model</em> is an object that only serves as a container for the hyperparameters of the model. A <em>machine</em> is an object wrapping both a model and data and can contain information on the <em>trained</em> model; it does <em>not</em> fit the model by itself. However, it does check that the model is compatible with the scientific type of the data and will warn you otherwise.</p>
<pre><code class="language-julia">tree_model = DecisionTreeClassifier()
tree = machine(tree_model, X, y)</code></pre><div class="code_output"><pre><code class="plaintext">[34mMachine{DecisionTreeClassifier} @ 1‚Ä¶44[39m</code></pre></div>
<p>A machine is used both for supervised and unsupervised model. In this tutorial we give an example for the supervised model first and then go on with the unsupervised case.</p>
<h2 id="training_and_testing_a_supervised_model"><a href="/pub/getting-started/fit-and-predict.html#training_and_testing_a_supervised_model">Training and testing a supervised model</a></h2>
<p>Now that you&#39;ve declared the model you&#39;d like to consider and the data, we are left with the standard training and testing step for a supervised learning algorithm.</p>
<h3 id="splitting_the_data"><a href="/pub/getting-started/fit-and-predict.html#splitting_the_data">Splitting the data</a></h3>
<p>To split the data into a <em>training</em> and <em>testing</em> set, you can use the function <code>partition</code> to obtain indices for data points that should be considered either as training or testing data:</p>
<pre><code class="language-julia">train, test = partition(eachindex(y), 0.7, shuffle=true)
test[1:3]</code></pre><div class="code_output"><pre><code class="plaintext">[72, 120, 25]</code></pre></div>
<h3 id="fitting_and_testing_the_machine"><a href="/pub/getting-started/fit-and-predict.html#fitting_and_testing_the_machine">Fitting and testing the machine</a></h3>
<p>To fit the machine, you can use the function <code>fit&#33;</code> specifying the rows to be used for the training:</p>
<pre><code class="language-julia">fit!(tree, rows=train)</code></pre><div class="code_output"><pre><code class="plaintext">[34mMachine{DecisionTreeClassifier} @ 1‚Ä¶44[39m</code></pre></div>
<p>Note that this <strong>modifies</strong> the machine which now contains the trained parameters of the decision tree. You can inspect the result of the fitting with the <code>fitresult</code> field of the model object:</p>
<pre><code class="language-julia">tree.fitresult</code></pre><div class="code_output"><pre><code class="plaintext">(DecisionTree.Node{Float64,CategoricalArrays.CategoricalString{UInt32}}(4, 0.75, DecisionTree.Leaf{CategoricalArrays.CategoricalString{UInt32}}(CategoricalArrays.CategoricalString{UInt32} "setosa", CategoricalArrays.CategoricalString{UInt32}["setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa", "setosa"]), DecisionTree.Node{Float64,CategoricalArrays.CategoricalString{UInt32}}(3, 4.75, DecisionTree.Leaf{CategoricalArrays.CategoricalString{UInt32}}(CategoricalArrays.CategoricalString{UInt32} "versicolor", CategoricalArrays.CategoricalString{UInt32}["versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor", "versicolor"]), DecisionTree.Node{Float64,CategoricalArrays.CategoricalString{UInt32}}(3, 5.05, DecisionTree.Node{Float64,CategoricalArrays.CategoricalString{UInt32}}(4, 1.75, DecisionTree.Leaf{CategoricalArrays.CategoricalString{UInt32}}(CategoricalArrays.CategoricalString{UInt32} "versicolor", CategoricalArrays.CategoricalString{UInt32}["versicolor", "versicolor", "versicolor"]), DecisionTree.Node{Float64,CategoricalArrays.CategoricalString{UInt32}}(1, 5.95, DecisionTree.Leaf{CategoricalArrays.CategoricalString{UInt32}}(CategoricalArrays.CategoricalString{UInt32} "versicolor", CategoricalArrays.CategoricalString{UInt32}["versicolor"]), DecisionTree.Leaf{CategoricalArrays.CategoricalString{UInt32}}(CategoricalArrays.CategoricalString{UInt32} "virginica", CategoricalArrays.CategoricalString{UInt32}["virginica", "virginica", "virginica", "virginica", "virginica"]))), DecisionTree.Leaf{CategoricalArrays.CategoricalString{UInt32}}(CategoricalArrays.CategoricalString{UInt32} "virginica", CategoricalArrays.CategoricalString{UInt32}["virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica", "virginica"])))), CategoricalArrays.CategoricalString{UInt32}["versicolor", "setosa", "virginica"])</code></pre></div>
<p>This <code>fitresult</code> will vary from model to model though classifiers will usually give out a tuple with the first element corresponding to the fitting and the second one keeping track of how classes are named &#40;so that predictions can be appropriately named&#41;.</p>
<p>You can now use the machine to make predictions with the <code>predict</code> function specifying rows to be used for the prediction:</p>
<pre><code class="language-julia">yÃÇ = predict(tree, rows=test)
@show yÃÇ[1]</code></pre><div class="code_output"><pre><code class="plaintext">≈∑[1] = UnivariateFinite(setosa=>0.01612903225806452, versicolor=>0.9677419354838711, virginica=>0.01612903225806452)
</code></pre></div>
<p>Note that the output is <em>probabilistic</em>, effectively a vector with a score for each class. You could get the mode by using the <code>mode</code> function on <code>yÃÇ</code> or using <code>predict_mode</code>:</p>
<pre><code class="language-julia">yÃÑ = predict_mode(tree, rows=test)
@show yÃÑ[1]
@show mode(yÃÇ[1])</code></pre><div class="code_output"><pre><code class="plaintext">»≥[1] = "versicolor"
mode(≈∑[1]) = "versicolor"
</code></pre></div>
<p>To measure the discrepancy between <code>yÃÇ</code> and <code>y</code> you could use the mean cross entropy:</p>
<pre><code class="language-julia">mce = cross_entropy(yÃÇ, y[test]) |> mean
round(mce, digits=4)</code></pre><div class="code_output"><pre><code class="plaintext">0.4877</code></pre></div>
<h2 id="unsupervised_models"><a href="/pub/getting-started/fit-and-predict.html#unsupervised_models">Unsupervised models</a></h2>
<p>Unsupervised models define a <code>transform</code> method, and may optionally implement an <code>inverse_transform</code> method. As in the supervised case, we use a machine to wrap the unsupervised model and the data:</p>
<pre><code class="language-julia">v = [1, 2, 3, 4]
stand_model = UnivariateStandardizer()
stand = machine(stand_model, v)</code></pre><div class="code_output"><pre><code class="plaintext">[34mMachine{UnivariateStandardizer} @ 7‚Ä¶84[39m</code></pre></div>
<p>We can then fit the machine and use it to apply the corresponding <em>data transformation</em>:</p>
<pre><code class="language-julia">fit!(stand)
w = transform(stand, v)
@show round.(w, digits=2)
@show mean(w)
@show std(w)</code></pre><div class="code_output"><pre><code class="plaintext">round.(w, digits=2) = [-1.16, -0.39, 0.39, 1.16]
mean(w) = 0.0
std(w) = 1.0
</code></pre></div>
<p>In this case, the model also has an inverse transform:</p>
<pre><code class="language-julia">vv = inverse_transform(stand, w)
sum(abs.(vv .- v))</code></pre><div class="code_output"><pre><code class="plaintext">0.0</code></pre></div>
<div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart. Last modified: October 10, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>
<!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/libs/pure/ui.min.js"></script>
  
  
      <script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
