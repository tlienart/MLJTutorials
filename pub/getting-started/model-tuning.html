<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/judoc.css"> <link rel=stylesheet  href="/css/pure.css"> <link rel=stylesheet  href="/css/side-menu.css"> <link rel=stylesheet  href="/css/extra.css"> <link rel=icon  href="/assets/infra/favicon.ico"> <title></title> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a href="/" id=menu-logo-link > <div class=menu-logo > <img id=menu-logo  alt="MLJ Logo" src="/assets/infra/MLJLogo2.svg" /> <p><strong>MLJ Tutorials</strong></p> </div> </a> <ul class=pure-menu-list > <li class="pure-menu-item pure-menu-top-item "><a href="/" class=pure-menu-link ><strong>Home</strong></a> <li class=pure-menu-sublist-title ><strong>Getting started</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/pub/getting-started/choosing-a-model.html" class=pure-menu-link >⊳ Choosing a model</a> <li class="pure-menu-item "><a href="/pub/getting-started/fit-and-predict.html" class=pure-menu-link >⊳ Fit, predict, transform</a> <li class="pure-menu-item pure-menu-selected"><a href="/pub/getting-started/model-tuning.html" class=pure-menu-link >⊳ Model tuning</a> <li class="pure-menu-item "><a href="/pub/getting-started/composing-models.html" class=pure-menu-link >⊳ Composing models</a> <li class="pure-menu-item "><a href="/pub/getting-started/learning-networks.html" class=pure-menu-link >⊳ Learning networks</a> </ul> <li class=pure-menu-sublist-title ><strong>End to end examples</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/pub/end-to-end/AMES.html" class=pure-menu-link >⊳ AMES</a> </ul> </ul> </div> </div> <div id=main > <div class=jd-content > <h1 id=tuning_a_model ><a href="/pub/getting-started/model-tuning.html#tuning_a_model">Tuning a model</a></h1> <div class=jd-toc ><ol><li><a href="/pub/getting-started/model-tuning.html#tuning_a_model">Tuning a model</a><ol><li><a href="/pub/getting-started/model-tuning.html#tuning_a_single_hyperparameter">Tuning a single hyperparameter</a><ol><li><a href="/pub/getting-started/model-tuning.html#specifying_a_range_of_value">Specifying a range of value</a><li><a href="/pub/getting-started/model-tuning.html#fitting_and_inspecting_a_tuned_model">Fitting and inspecting a tuned model</a></ol><li><a href="/pub/getting-started/model-tuning.html#tuning_nested_hyperparameters">Tuning nested hyperparameters</a></ol></ol></div> <h2 id=tuning_a_single_hyperparameter ><a href="/pub/getting-started/model-tuning.html#tuning_a_single_hyperparameter">Tuning a single hyperparameter</a></h2> <p>In MLJ, tuning is implemented as a model wrapper. After wrapping a model in a <em>tuning strategy</em> &#40;e.g. cross-validation&#41; and binding the wrapped model to data in a <em>machine</em>, fitting the machine initiates a search for optimal model hyperparameters.</p> <p>Let&#39;s use a decision tree classifier and tune the maximum depth of the tree. As usual, start by loading data and the model</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> MLJ
X, y = <span class=hljs-meta >@load_iris</span>
<span class=hljs-meta >@load</span> DecisionTreeClassifier</code></pre><div class=code_output ><pre><code class="plaintext hljs">DecisionTreeClassifier @ 8…58</code></pre></div>
<h3 id=specifying_a_range_of_value ><a href="/pub/getting-started/model-tuning.html#specifying_a_range_of_value">Specifying a range of value</a></h3>
<p>To specify a range of value, you can use the <code>range</code> function:</p>
<pre><code class="julia hljs">dtc = DecisionTreeClassifier()
r   = range(dtc, :max_depth, lower=<span class=hljs-number >1</span>, upper=<span class=hljs-number >5</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">NumericRange @ 2…97</code></pre></div>
<p>As you can see, the range function takes a model &#40;<code>dtc</code>&#41;, a symbol for the hyperparameter of interest &#40;<code>:max_depth</code>&#41; and indication of how to samples values. You can either manually specify an iterator over values by using the <code>values&#61;</code> keyword or, where appropriate, use the <code>lower</code> and <code>upper</code> keywords which help define such an iterator between bounds.</p>
<p>Once a range of value has been defined, you can then wrap the model in a <code>TunedModel</code> specifying the tuning strategy:</p>
<pre><code class="julia hljs">tm = TunedModel(model=dtc, ranges=[r, ], measure=cross_entropy)</code></pre><div class=code_output ><pre><code class="plaintext hljs">ProbabilisticTunedModel @ 1…42</code></pre></div>
<h3 id=fitting_and_inspecting_a_tuned_model ><a href="/pub/getting-started/model-tuning.html#fitting_and_inspecting_a_tuned_model">Fitting and inspecting a tuned model</a></h3>
<p>To fit a tuned model, you can use the usual syntax:</p>
<pre><code class="julia hljs">m = machine(tm, X, y)
fit!(m)</code></pre><div class=code_output ><pre><code class="plaintext hljs">Machine{ProbabilisticTunedModel} @ 1…42</code></pre></div>
<p>In order to inspect the best model, you can use the function <code>fitted_params</code> on the machine and inspect the <code>best_model</code> field:</p>
<pre><code class="julia hljs">fitted_params(m).best_model.max_depth</code></pre><div class=code_output ><pre><code class="plaintext hljs">3</code></pre></div>
<h2 id=tuning_nested_hyperparameters ><a href="/pub/getting-started/model-tuning.html#tuning_nested_hyperparameters">Tuning nested hyperparameters</a></h2>
<p>Let&#39;s generate simple dummy regression data</p>
<pre><code class="julia hljs">best_k = fitted_params(self_tuning_kc).best_model.K
<span class=hljs-meta >@show</span> best_k</code></pre><div class=code_output ><pre><code class="plaintext hljs">best_k = 5
</code></pre></div>
<p>Let&#39;s then build a simple ensemble model with decision tree regressors:</p>
<pre><code class="julia hljs">dtr = <span class=hljs-meta >@load</span> DecisionTreeRegressor
forest = EnsembleModel(atom=dtr)</code></pre><div class=code_output ><pre><code class="plaintext hljs">DeterministicEnsembleModel{DecisionTreeRegressor} @ 1…49</code></pre></div>
<p>Such a model has <em>nested</em> hyperparameters in that the ensemble has hyperparameters &#40;e.g. the <code>:bagging_fraction</code>&#41; and the atom has hyperparameters &#40;e.g. <code>:n_subfeatures</code> or <code>:max_depth</code>&#41;.</p>
<p>Range for nested hyperparameters are specified using dot syntax, the rest is done in much the same way as before:</p>
<pre><code class="julia hljs">r1 = range(forest, :(atom.n_subfeatures), lower=<span class=hljs-number >1</span>, upper=<span class=hljs-number >3</span>)
r2 = range(forest, :bagging_fraction, lower=<span class=hljs-number >0.4</span>, upper=<span class=hljs-number >1.0</span>)
tm = TunedModel(model=forest, tuning=Grid(resolution=<span class=hljs-number >12</span>),
                resampling=CV(nfolds=<span class=hljs-number >6</span>), ranges=[r1, r2],
                measure=rms)
m = machine(tm, X, y)
fit!(m);</code></pre>
<p>A useful function to inspect a model after fitting it is the <code>report</code> function which collects information on the model and the tuning, for instance you can use it to recover the best measurement:</p>
<pre><code class="julia hljs">report(m)</code></pre><div class=code_output ><pre><code class="plaintext hljs">(parameter_names = ["atom.n_subfeatures" "bagging_fraction"], parameter_scales = Symbol[:linear :linear], parameter_values = Any[1 0.4; 2 0.4; 3 0.4; 1 0.45454545454545453; 2 0.45454545454545453; 3 0.45454545454545453; 1 0.509090909090909; 2 0.509090909090909; 3 0.509090909090909; 1 0.5636363636363636; 2 0.5636363636363636; 3 0.5636363636363636; 1 0.6181818181818182; 2 0.6181818181818182; 3 0.6181818181818182; 1 0.6727272727272727; 2 0.6727272727272727; 3 0.6727272727272727; 1 0.7272727272727273; 2 0.7272727272727273; 3 0.7272727272727273; 1 0.7818181818181819; 2 0.7818181818181819; 3 0.7818181818181819; 1 0.8363636363636363; 2 0.8363636363636363; 3 0.8363636363636363; 1 0.8909090909090909; 2 0.8909090909090909; 3 0.8909090909090909; 1 0.9454545454545454; 2 0.9454545454545454; 3 0.9454545454545454; 1 1.0; 2 1.0; 3 1.0], measurements = [0.3612674125448781, 0.22521634096578433, 0.25150628231499333, 0.3240377704641391, 0.21537047633386078, 0.2314348325579357, 0.329566632258063, 0.2136904038896812, 0.21893553159453338, 0.3149863482013637, 0.2041691057566936, 0.2012163505347194, 0.2951116837573357, 0.19303413687148688, 0.1899173392366427, 0.2947106845160576, 0.18540465709561968, 0.18615824980893017, 0.28542384681257854, 0.18905084768858527, 0.18050531995313304, 0.28589633148083243, 0.18256422809549308, 0.17752061037739827, 0.27931388265365803, 0.1804193761331968, 0.17452534762007996, 0.2856969543875924, 0.1783023986629015, 0.1782741662228021, 0.2682021129526709, 0.17720353232414887, 0.18334086322902385, 0.2736111036447451, 0.17348069211621034, 0.2053441489521491], best_measurement = 0.17348069211621034)</code></pre></div>
<div class=page-foot >
  <div class=copyright >
    &copy; Thibaut Lienart. Last modified: October 09, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>

      </div> 
  </div> 
  <script src="/libs/pure/ui.min.js"></script>